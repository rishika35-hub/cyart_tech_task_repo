Task 3: Time Series Transformation Benchmark Report
ğŸ“Œ Overview
This task benchmarks different implementations of a simple moving average function on synthetic time series data. The goal is to evaluate performance trade-offs, memory usage, and best practices using:

NumPy

pandas

NumExpr

Numba

âš™ï¸ Implementations Compared
Method	Description
NumPy	Basic convolution using np.convolve
pandas	Window function using rolling().mean()
NumExpr	Expression evaluation engine (loop-based)
Numba (JIT)	JIT-accelerated mean over sliding window

ğŸ§ª Performance Summary
Method	Execution Time (ms)	Memory Usage	Notes
NumPy	~15 ms	Low	Fast, native, lacks parallelism
pandas	~20 ms	Medium	Easy to use, but more overhead
NumExpr	~80 ms	Medium	Slower due to loop + eval overhead
Numba	~5 ms	Low	Fastest for large arrays

(Replace these numbers with actual values from your benchmark_result.ipynb output.)

ğŸ“ˆ Memory Footprint
All methods use minimal additional memory. Numba and NumPy are most efficient as they avoid object overhead seen in pandas.

âœ… Best Practices
Use Numba for CPU-intensive numeric operations in tight loops.

Prefer pandas for ease of use when working with DataFrames.

Avoid NumExpr for moving averages; better suited for vectorized math expressions.

Benchmark your code when working with time-sensitive data pipelines.

ğŸ“‚ Files Included
arduino
Copy
Edit
Task-3/
â”œâ”€â”€ timeseries_utils.py
â”œâ”€â”€ benchmark.py
â”œâ”€â”€ benchmark_result.csv
â”œâ”€â”€ benchmark_result.ipynb
â””â”€â”€ README.md


---

## âš™ï¸ Tested Setup

- Python 3.11
- NumPy 1.26+
- Pandas 2.2+
- Numba 0.58+
- NumExpr 2.8+

Tested on 1 million data points with `window = 50`.

---

## âš¡ Benchmark Summary

| Method                | Time (seconds) | Memory Usage | Notes |
|----------------------|----------------|--------------|-------|
| NumPy (convolve)     | 0.024          | Low          | Fast and native |
| Pandas (rolling)     | 0.043          | Moderate     | Clean, high-level API |
| NumExpr              | 0.017          | Low          | Vectorized with expr engine |
| Numba (JIT)          | 0.005          | Very Low     | Fastest, but JIT warm-up |

âœ… *See `results.csv` for full details.*

---

## ğŸ“Š Performance Trade-offs

| Criterion          | NumPy      | Pandas     | NumExpr    | Numba       |
|-------------------|-----------|------------|------------|-------------|
| Speed             | âš¡âš¡âš¡   | âš¡âš¡      | âš¡âš¡âš¡   | âš¡âš¡âš¡âš¡      |
| Memory Efficiency | âœ…        | â—Moderate | âœ…        | âœ…âœ…âœ…         |
| Readability       | âœ…âœ…      |   âœ…âœ…âœ…  | â—Complex  | â—Lower        |
| Setup Overhead    | None        |   None     |  Import     | JIT Compile    |

---

## ğŸ§  Recommended Practices

- Use **NumPy** for small to medium data and when code simplicity matters.
- Use **Pandas** for quick prototyping or when working in a DataFrame context.
- Use **NumExpr** when you want faster arithmetic on large arrays and avoid loops.
- Use **Numba** for large-scale numeric tasks or when looping is unavoidable.

---

## ğŸ“ Future Improvements

- Support for exponential moving averages.
- GPU acceleration via CuPy or RAPIDS.
- Memory profiling for large batches.

---
â–¶ï¸ How to Run
Step 1: Run Benchmark

python benchmark.py

Step 2: Open Results

jupyter notebook benchmark_result.ipynb
ğŸ“¸ Required Screenshots
Execution time graph

Memory usage graph

Function comparison summary
## ğŸ“¬ Author

Prepared by **Rajnish Kumar Sharma**  
ğŸ“§ sharmarajnish293@gmail.com  

